# final_training_fixed.py
import torch
import torch.nn as nn
#import torch.nn.functional as F
import torch.optim as optim
from torch.optim.swa_utils import AveragedModel
from torch.utils.data import DataLoader, random_split, Subset
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
import torchvision.models as models
import numpy as np
from sklearn.metrics import precision_score, recall_score
import os
import time

# ========== –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê GPU ==========
print("=" * 60)
print("ü§ñ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´ GOOGLE COLAB")
print("=" * 60)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"‚úÖ GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞: {torch.cuda.get_device_name(0)}")
    print(f"   –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    print(f"   CUDA: {torch.version.cuda}")
else:
    device = torch.device("cpu")
    print("‚ùå GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")

print(f"‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
print("-" * 60)

class Bottleneck(nn.Module):
    """Bottleneck block –¥–ª—è ResNet50/101/152"""
    expansion = 4  # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤ –≤ 4 —Ä–∞–∑–∞

    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(Bottleneck, self).__init__()

        # 1x1 —Å–≤—ë—Ä—Ç–∫–∞ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)

        # 3x3 —Å–≤—ë—Ä—Ç–∫–∞
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,
                               stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # 1x1 —Å–≤—ë—Ä—Ç–∫–∞ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,
                               kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)

        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity  # Residual connection
        out = self.relu(out)

        return out


class ResNet50(nn.Module):
    """–†–µ–∞–ª–∏–∑–∞—Ü–∏—è ResNet50 —Å –Ω—É–ª—è"""

    def __init__(self, num_classes=120, zero_init_residual=False):
        super(ResNet50, self).__init__()

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ResNet50
        self.in_channels = 64

        # –ù–∞—á–∞–ª—å–Ω—ã–µ —Å–ª–æ–∏
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # ResNet —Å–ª–æ–∏
        self.layer1 = self._make_layer(Bottleneck, 64, 3, stride=1)
        self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)
        self.layer3 = self._make_layer(Bottleneck, 256, 6, stride=2)
        self.layer4 = self._make_layer(Bottleneck, 512, 3, stride=2)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        self._initialize_weights(zero_init_residual)

    def _make_layer(self, block, out_channels, blocks, stride=1):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ—è ResNet"""
        downsample = None

        # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä—ã (stride != 1 –∏–ª–∏ –∫–∞–Ω–∞–ª—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç)
        if stride != 1 or self.in_channels != out_channels * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.in_channels, out_channels * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * block.expansion)
            )

        layers = []
        # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫ –≤ —Å–ª–æ–µ –º–æ–∂–µ—Ç –∏–º–µ—Ç—å downsample
        layers.append(block(self.in_channels, out_channels, stride, downsample))

        self.in_channels = out_channels * block.expansion

        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏
        for _ in range(1, blocks):
            layers.append(block(self.in_channels, out_channels))

        return nn.Sequential(*layers)

    def _initialize_weights(self, zero_init_residual):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π ResNet"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize –ø–æ—Å–ª–µ–¥–Ω–∏–π BatchNorm –≤ –∫–∞–∂–¥–æ–º residual branch
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck):
                    nn.init.constant_(m.bn3.weight, 0)

    def forward(self, x):
        # –ù–∞—á–∞–ª—å–Ω—ã–µ —Å–ª–æ–∏
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        # ResNet —Å–ª–æ–∏
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)

        return x

def setup_environment():
    # –í Colab –¥–∞—Ç–∞—Å–µ—Ç –±—É–¥–µ—Ç –≤ /content –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    # –ù–∞ –ª–æ–∫–∞–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É —Ç–∞–∫–æ–π: "C:/Users/1/.cache/kagglehub/datasets/jessicali9530/stanford-dogs-dataset/versions/2/images"
    data_dir = "/content/dogs"  # –ü—É—Ç—å –ø–æ—Å–ª–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU
    if torch.cuda.is_available():
        print(f"üìä –ü–∞–º—è—Ç—å GPU –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏: {torch.cuda.memory_allocated() / 1e9:.2f} GB")

    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    return device, data_dir


def prepare_dataloaders_smart(data_dir, batch_size=256, max_images=12000):
    IMAGENET_MEAN = [0.485, 0.456, 0.406]
    IMAGENET_STD = [0.229, 0.224, 0.225]

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –û–î–ò–ù –¥–∞—Ç–∞—Å–µ—Ç –±–µ–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
    full_dataset = ImageFolder(
        root=os.path.join(data_dir, 'Images'),
        transform=None  # –ü–æ–∫–∞ –±–µ–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
    )

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    if len(full_dataset) > max_images:
        indices = torch.randperm(len(full_dataset))[:max_images]
        dataset = Subset(full_dataset, indices)
        print(f"  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {max_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    else:
        dataset = full_dataset

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val/test
    total_size = len(dataset)
    train_size = int(0.7 * total_size)
    val_size = int(0.15 * total_size)
    test_size = total_size - train_size - val_size

    # –í–ê–ñ–ù–û: seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    generator = torch.Generator().manual_seed(42)
    train_indices, val_indices, test_indices = random_split(
        range(total_size),
        [train_size, val_size, test_size],
        generator=generator
    )

    # –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    transform_train = transforms.Compose([
        transforms.Resize(128),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.CenterCrop(112),
        transforms.ToTensor(),
        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
    ])

    transform_val_test = transforms.Compose([
        transforms.Resize(128),
        transforms.CenterCrop(112),
        transforms.ToTensor(),
        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
    ])

    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏
    class TransformedSubset(Subset):
        """–ü–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å —Å–≤–æ–µ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""

        def __init__(self, dataset, indices, transform=None):
            super().__init__(dataset, indices)
            self.transform = transform

        def __getitem__(self, idx):
            x, y = self.dataset[self.indices[idx]]
            if self.transform:
                x = self.transform(x)
            return x, y

    train_dataset = TransformedSubset(full_dataset, train_indices, transform_train)
    val_dataset = TransformedSubset(full_dataset, val_indices, transform_val_test)
    test_dataset = TransformedSubset(full_dataset, test_indices, transform_val_test)

    # –°–æ–∑–¥–∞–µ–º DataLoader
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,
                              num_workers=2, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,
                            num_workers=2, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,
                             num_workers=2, pin_memory=True)

    print(f"–ö–ª–∞—Å—Å–æ–≤: {len(full_dataset.classes)}")
    print(f"–î–∞–Ω–Ω—ã–µ: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}")

    return train_loader, val_loader, test_loader, full_dataset.classes


def create_model(pretrained=True, num_classes=120, device=None):
    """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"\nüîß –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ {device}")

    if pretrained:
        from torchvision.models import ResNet50_Weights
        model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)
        model.fc = nn.Linear(model.fc.in_features, num_classes)
        print(" –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è ResNet50")
    else:
        #model = models.resnet50(weights=None)
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è ResNet50 —Å –Ω—É–ª—è
        model = ResNet50(num_classes = num_classes)
        print(" ResNet50 —Å –Ω—É–ª—è")

    # –ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    model = model.to(device)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞
    print(f"üìè –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in model.parameters()):,}")
    print(f"üìç –ú–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {next(model.parameters()).device}")

    return model


def calculate_metrics(model, data_loader, device):
    """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫"""
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))
    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)

    return accuracy, precision, recall


def train_model_unified(model, train_loader, val_loader, device,
                        use_swa=False, num_epochs=30, is_pretrained=True):

    criterion = nn.CrossEntropyLoss().to(device)

    if is_pretrained:
        print("=" * 60)
        print("–†–ï–ñ–ò–ú: Fine-tuning –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
        print("   –ü–µ—Ä–≤—ã–µ —Å–ª–æ–∏ (conv1, layer1, layer2) –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã")
        print("=" * 60)

        # === –®–ê–ì 1: –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –í–°–ï —Å–ª–æ–∏ ===
        for param in model.parameters():
            param.requires_grad = False

        # === –§–ê–ó–ê 1: –û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (5 —ç–ø–æ—Ö) ===
        print("\n–§–∞–∑–∞ 1: –û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (5 —ç–ø–æ—Ö)")
        print("   –û–±—É—á–∞–µ—Ç—Å—è: fc (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä)")
        print("   –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–∏ –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã")

        # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –¢–û–õ–¨–ö–û –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        for param in model.fc.parameters():
            param.requires_grad = True

        optimizer = optim.Adam(model.fc.parameters(), lr=0.01)
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)

        for epoch in range(5):
            model.train()
            total_loss = 0

            for inputs, labels in train_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            scheduler.step()
            val_acc, _, _ = calculate_metrics(model, val_loader, device)
            print(f"   –≠–ø–æ—Ö–∞ {epoch + 1:2d}: "
                  f"Loss={total_loss / len(train_loader):.4f}, "
                  f"Val Acc={val_acc:.4f}")

        # === –§–ê–ó–ê 2: –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º layer4 (10 —ç–ø–æ—Ö) ===
        print("\n–§–∞–∑–∞ 2: –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º layer4 (10 —ç–ø–æ—Ö)")
        print("   –û–±—É—á–∞—é—Ç—Å—è: layer4, fc")
        print("   –ó–∞–º–æ—Ä–æ–∂–µ–Ω—ã: conv1, layer1, layer2, layer3")

        # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –¢–û–õ–¨–ö–û layer4
        for param in model.layer4.parameters():
            param.requires_grad = True

        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è layer4 + fc
        trainable_params = filter(lambda p: p.requires_grad, model.parameters())
        optimizer = optim.Adam(trainable_params, lr=0.001)
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)

        for epoch in range(10):
            model.train()
            total_loss = 0

            for inputs, labels in train_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            scheduler.step()
            val_acc, _, _ = calculate_metrics(model, val_loader, device)
            print(f"   –≠–ø–æ—Ö–∞ {epoch + 6:2d}: "
                  f"Loss={total_loss / len(train_loader):.4f}, "
                  f"Val Acc={val_acc:.4f}")

        # === –§–ê–ó–ê 3: –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º layer3 (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ) ===
        dataset_size = len(train_loader.dataset)
        remaining_epochs = num_epochs - 15

        if dataset_size > 10000:  # –î–ª—è Stanford Dogs (20k) - —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º
            print(f"\n–§–∞–∑–∞ 3: –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º layer3 ({remaining_epochs} —ç–ø–æ—Ö)")
            print("   –û–±—É—á–∞—é—Ç—Å—è: layer3, layer4, fc")
            print("   –ó–∞–º–æ—Ä–æ–∂–µ–Ω—ã: conv1, layer1, layer2")

            # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º layer3
            for param in model.layer3.parameters():
                param.requires_grad = True

            # –ù–æ–≤—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è layer3 + layer4 + fc
            trainable_params = filter(lambda p: p.requires_grad, model.parameters())
            optimizer = optim.Adam(trainable_params, lr=0.0001)  # –ú–µ–Ω—å—à–∏–π LR –¥–ª—è layer3
            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

        else:
            print(f"\n–§–∞–∑–∞ 3: –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ layer4 + fc ({remaining_epochs} —ç–ø–æ—Ö)")
            print("   –û–±—É—á–∞—é—Ç—Å—è: layer4, fc")
            print("   –ó–∞–º–æ—Ä–æ–∂–µ–Ω—ã: conv1, layer1, layer2, layer3")
            # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ—Ç –∂–µ (—Ç–æ–ª—å–∫–æ layer4 + fc)
            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

    else:  # –û–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è
        print("=" * 50)
        print("–†–ï–ñ–ò–ú: –û–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è")
        print("=" * 50)

        for param in model.parameters():
            param.requires_grad = True

        optimizer = optim.Adam(model.parameters(), lr=0.01)
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
        remaining_epochs = num_epochs

    # === –û–ë–©–ê–Ø –§–ê–ó–ê –û–ë–£–ß–ï–ù–ò–Ø ===
    print(f"\n–û—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ({remaining_epochs} —ç–ø–æ—Ö)")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ —Å–ª–æ–∏ –æ–±—É—á–∞—é—Ç—Å—è
    trainable_layers = []
    for name, param in model.named_parameters():
        if param.requires_grad and name.split('.')[0] not in trainable_layers:
            trainable_layers.append(name.split('.')[0])

    print(f"   –û–±—É—á–∞–µ–º—ã–µ —Å–ª–æ–∏: {', '.join(sorted(set(trainable_layers)))}")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ SWA
    swa_model = None
    if use_swa:
        swa_model = AveragedModel(model).to(device)
        swa_start = int(remaining_epochs * 0.7)  # –ù–∞—á–∏–Ω–∞–µ–º —Å 70% —ç–ø–æ—Ö
        print(f"   SWA –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è —Å —ç–ø–æ—Ö–∏ {swa_start}")

    for epoch in range(remaining_epochs):
        model.train()
        total_loss = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        # SWA –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        if use_swa and swa_model and (epoch >= swa_start):
            swa_model.update_parameters(model)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ LR
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']

        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        val_acc, _, _ = calculate_metrics(model, val_loader, device)

        print(f"   –≠–ø–æ—Ö–∞ {epoch + 1:3d}: "
              f"Loss={total_loss / len(train_loader):.4f}, "
              f"Val Acc={val_acc:.4f}, "
              f"LR={current_lr:.6f}")

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ SWA
    if use_swa and swa_model:
        torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)
        print(" SWA –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞")
        return swa_model

    return model


def main():
    print("=" * 60)
    print(" –°–†–ê–í–ù–ï–ù–ò–ï –ú–ï–¢–û–î–û–í –û–ë–£–ß–ï–ù–ò–Ø - Stanford Dogs")
    print("=" * 60)

    total_start = time.time()
    device, data_dir = setup_environment()
    BATCH_SIZE = 256 # –î–ª—è GPU –Ω–æ—Ä–º–∞–ª—å–Ω–æ

    train_loader, val_loader, test_loader, classes = prepare_dataloaders_smart(data_dir, batch_size=BATCH_SIZE, max_images=12000)

    results = {}

    # –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 1: –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è + Adam (10 —ç–ø–æ—Ö)
    print("\n" + "=" * 50)
    print(" –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 1: –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è + Adam")
    print("=" * 50)

    exp1_start = time.time()
    model1 = create_model(pretrained=True, num_classes=120, device=device)
    model1 = train_model_unified(model1, train_loader, val_loader, device,
                                 use_swa=False, num_epochs=30, is_pretrained=True)

    test_acc1, test_prec1, test_rec1 = calculate_metrics(model1, test_loader, device)
    results['Pretrained+Adam'] = {'accuracy': test_acc1, 'precision': test_prec1, 'recall': test_rec1}

    # –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 2: –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è + Averaged Adam (10 —ç–ø–æ—Ö)
    print("\n" + "=" * 50)
    print(" –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 2: –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è + Averaged Adam")
    print("=" * 50)

    exp2_start = time.time()
    model2 = create_model(pretrained=True)
    model2 = train_model_unified(model2, train_loader, val_loader, device,
                                 use_swa=True, num_epochs=10, is_pretrained=True)

    test_acc2, test_prec2, test_rec2 = calculate_metrics(model2, test_loader, device)
    results['Pretrained+AveragedAdam'] = {'accuracy': test_acc2, 'precision': test_prec2, 'recall': test_rec2}
    #
    # –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 3: –° –Ω—É–ª—è + Adam (10 —ç–ø–æ—Ö)
    # print("\n" + "=" * 50)
    # print(" –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 3: –û–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è + Adam")
    # print("=" * 50)
    # print(" –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: ResNet50 —Å –Ω—É–ª—è —Ç—Ä–µ–±—É–µ—Ç 50+ —ç–ø–æ—Ö")
    #
    # exp3_start = time.time()
    # model3 = create_model(pretrained=False)
    # model3 = train_model_unified(model3, train_loader, val_loader, device,
    #                              use_swa=False, num_epochs=10, is_pretrained=False)
    #
    # test_acc3, test_prec3, test_rec3 = calculate_metrics(model3, test_loader, device)
    # results['Scratch+Adam'] = {'accuracy': test_acc3, 'precision': test_prec3, 'recall': test_rec3}

    # –†–ï–ó–£–õ–¨–¢–ê–¢–´
    print("\n" + "=" * 60)
    print(" –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("=" * 60)

    for name, metrics in results.items():
        print(f"\n{name}:")
        print(f"  Accuracy:  {metrics['accuracy']:.4f}")
        print(f"  Precision: {metrics['precision']:.4f}")
        print(f"  Recall:    {metrics['recall']:.4f}")

    total_time = (time.time() - total_start) / 60
    print(f"\n –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –ó–ê {total_time:.1f} –ú–ò–ù–£–¢")

    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print(f"\nüßπ –ü–∞–º—è—Ç—å GPU –æ—á–∏—â–µ–Ω–∞")


if __name__ == "__main__":
    main()